{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f7775ca-be85-4b58-8855-371bd716eb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "performance_level\n",
       "Medium    521\n",
       "Low       285\n",
       "High      194\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['gender', 'race_ethnicity', 'parental_level_of_education', 'lunch', 'test_preparation_course']\n",
      "Numeric columns: ['math_score', 'reading_score', 'writing_score']\n",
      "Test Accuracy: 0.9650\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.97      0.95      0.96        39\n",
      "         Low       1.00      0.93      0.96        57\n",
      "      Medium       0.94      0.99      0.97       104\n",
      "\n",
      "    accuracy                           0.96       200\n",
      "   macro avg       0.97      0.96      0.96       200\n",
      "weighted avg       0.97      0.96      0.96       200\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Low</th>\n",
       "      <th>Pred Medium</th>\n",
       "      <th>Pred High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medium</th>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pred Low  Pred Medium  Pred High\n",
       "Low           53            4          0\n",
       "Medium         0          103          1\n",
       "High           0            2         37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Feature Importances:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "writing_score                                     0.337505\n",
       "reading_score                                     0.318719\n",
       "math_score                                        0.237338\n",
       "gender_male                                       0.011083\n",
       "gender_female                                     0.010495\n",
       "lunch_free/reduced                                0.008879\n",
       "test_preparation_course_none                      0.007899\n",
       "lunch_standard                                    0.006858\n",
       "test_preparation_course_completed                 0.006410\n",
       "parental_level_of_education_high school           0.006334\n",
       "race_ethnicity_group E                            0.006276\n",
       "race_ethnicity_group C                            0.005913\n",
       "race_ethnicity_group D                            0.005566\n",
       "parental_level_of_education_some college          0.005507\n",
       "parental_level_of_education_some high school      0.004962\n",
       "parental_level_of_education_associate's degree    0.004852\n",
       "race_ethnicity_group B                            0.004598\n",
       "parental_level_of_education_bachelor's degree     0.004029\n",
       "race_ethnicity_group A                            0.003716\n",
       "parental_level_of_education_master's degree       0.003062\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['student_performance_pipeline.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full pipeline with corrected column names\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv(\"study_performance.csv\")\n",
    "\n",
    "# Create target\n",
    "df['avg_score'] = df[['math_score', 'reading_score', 'writing_score']].mean(axis=1)\n",
    "def score_label(x):\n",
    "    if x < 60:\n",
    "        return 'Low'\n",
    "    elif x <= 80:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "df['performance_level'] = df['avg_score'].apply(score_label)\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "display(df['performance_level'].value_counts())\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['avg_score','performance_level'])\n",
    "y = df['performance_level']\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('clf', clf)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=['Low','Medium','High'])\n",
    "cm_df = pd.DataFrame(cm, index=['Low','Medium','High'], columns=['Pred Low','Pred Medium','Pred High'])\n",
    "print(\"Confusion Matrix:\")\n",
    "display(cm_df)\n",
    "\n",
    "# Feature importances\n",
    "ohe = pipe.named_steps['preprocessor'].named_transformers_['cat']\n",
    "try:\n",
    "    ohe_feature_names = list(ohe.get_feature_names_out(categorical_cols))\n",
    "except Exception:\n",
    "    ohe_feature_names = []\n",
    "    for i, col in enumerate(categorical_cols):\n",
    "        cats = ohe.categories_[i]\n",
    "        ohe_feature_names += [f\"{col}_{c}\" for c in cats]\n",
    "\n",
    "feature_names = numeric_cols + ohe_feature_names\n",
    "importances = pipe.named_steps['clf'].feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False).head(20)\n",
    "print(\"\\nTop 20 Feature Importances:\")\n",
    "display(feat_imp)\n",
    "feat_imp.to_csv('feature_importances.csv')\n",
    "\n",
    "# Save pipeline and streamlit app\n",
    "model_path = \"student_performance_pipeline.joblib\"\n",
    "joblib.dump(pipe, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35824021-f69b-44ae-aa82-04fc0f144007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
